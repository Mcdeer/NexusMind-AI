# 🚀 NexusMind AI 项目开发日志 (Development Log)

**开发者：** [Modeler]
**项目周期：** 2026.01.27 - 2026.01.28 
**核心架构：** Next.js 14 (App Router) + NestJS + Prisma + PostgreSQL + Redis + SSE Streaming

---

## 📅 Day 1: 地基搭建与 UI 骨架工程

### 🎯 阶段目标
初始化前后端工程环境，建立"工业级"开发规范，完成响应式侧边栏与聊天布局。

### 🏗 架构决策
1.  **前后端分离 (Monorepo-like):** 根目录下拆分 `frontend` 和 `backend`。理由：解耦开发逻辑，便于后续分别进行容器化部署。
2.  **基础设施即代码 (IaC):** 使用 `docker-compose.yml` 编排 PostgreSQL、Redis 和 pgAdmin。理由：确保环境一致性，实现"即开即用"。
3.  **UI 库选择 (Shadcn/UI):** 放弃 AntD 等传统库，选择基于 Tailwind 的源码级组件库。理由：极致的定制化能力，符合现代 AI 应用的审美标准。

### 🛠 遇到问题与解决方案
*   **问题 1：Windows PowerShell 脚本执行策略拦截。**
    *   *描述：* 尝试运行 `npm run dev` 时报错 `PSSecurityException`。
    *   *解决：* 理解了 Windows 策略保护机制，通过 `Set-ExecutionPolicy RemoteSigned` 在用户域放行脚本执行。
*   **问题 2：pgAdmin 容器启动失败。**
    *   *描述：* 日志显示 `.local` 邮箱域名校验失败。
    *   *解决：* 定位到 pgAdmin 4 的严格正则校验，将默认邮箱改为标准的 `admin@admin.com`，顺利拉起数据库可视化界面。

---

## 📅 Day 2: 全栈打通、AI 集成与深度性能调优

### 🎯 阶段目标
实现数据库持久化，接入大模型流式响应，解决高并发下的状态一致性 Bug。

### 🏗 架构决策
1.  **ORM 层 (Prisma):** 使用 Prisma 7.x。理由：类型安全，自动生成的 Client 能极大减少 SQL 手写错误，提高开发效率。
2.  **全局状态管理 (React Context):** 引入 `ChatContext` 统一管理对话列表和消息流。理由：避免组件层级过深导致的"Props Drilling"，确保侧边栏与主区域数据同步。
3.  **实时传输协议 (SSE):** 采用 Server-Sent Events 实现流式响应。理由：相比于 WebSocket，SSE 在 AI 对话这种单向流场景下更轻量，且天然兼容 HTTP。

### 🛠 遇到问题与解决方案（核心攻坚）
*   **问题 3：Prisma 7 引擎类型报错。**
    *   *描述：* 报错 `Using engine type "client" requires adapter...`。
    *   *原因：* 深入调研发现 Prisma 7 默认推荐边缘端配置。
    *   *解决：* 修改 `schema.prisma` 和 `prisma.config.ts`，将引擎强制设为 `library`，匹配本地 Node.js 环境。
*   **问题 4：AI 接口余额不足 (402 Error)。**
    *   *解决：* 实现了 API 的**优雅降级与适配层**。代码支持通过环境变量无缝切换云端 DeepSeek 与本地 Ollama (Llama 3)，增强了系统的灵活性。
*   **问题 5：AI 接口异常处理缺失，用户体验差。**
    *   *描述：* 当 API 返回 402（余额不足）、401（认证失败）等错误时，系统直接抛出异常，用户看到的是技术性错误信息。
    *   *解决思路：* 实现**分层错误处理架构**：
        *   后端：在 `ai.service.ts` 中捕获 HTTP 状态码（401/402/403/429/500/503），将技术错误转换为友好的中文提示（如"AI 服务暂时不可用，请检查余额或配置"）。
        *   前端：改进流式解析逻辑，识别错误类型，用红色高亮和提示框展示；添加"重试"按钮，允许用户一键重试失败的消息。
        *   配置：创建 `.env.example`，详细说明如何切换本地 Ollama 和云端 DeepSeek，提升开发者体验。
    *   *技术亮点：* 错误处理不是简单的 try-catch，而是**用户友好的错误映射层**，将底层 API 错误转换为业务语义。
*   **问题 6：核心 Bug——AI 回复在流式结束后消失（第一次修复尝试）。**
    *   *诊断：* 确认为**竞态条件 (Race Condition)**。后端 `COMMIT` 数据库与前端 `Re-fetch` 接口的时间差导致前端查到了旧的空数据。
    *   *第一次修复（Hack 方案）：* 增加延迟刷新（500ms、1000ms），添加智能验证逻辑。**问题：** 这是典型的"用时间换正确性"的 hack，存在不可预知的竞态风险。
    *   *反思：* 意识到**延迟不是解决方案，而是掩盖问题的遮羞布**。真正的解决方案应该是消除竞态条件的根源。
*   **问题 7：AI 回复消失问题的彻底修复（架构级重构）。**
    *   *核心策略转变：* 从"流式结束后立即全量刷新（Re-fetch）"改为"**状态本地固化（State Persistence）**"。
    *   *后端重构：*
        *   确保 `Prisma.message.create` 在 SSE 流关闭前被 `await` 完成，保证消息已持久化。
        *   在流的最后发送特殊事件 `complete`，包含消息在数据库中的真实 `id`。
        *   **关键点：** 消息保存和流关闭的时序保证，消除了竞态条件的根源。
    *   *前端重构：*
        *   删除所有 `setTimeout` 延迟逻辑（清理了所有 hack 代码）。
        *   流式结束时，禁止立即调用 `fetchChat` 或重新获取整个消息数组。
        *   当收到 `complete` 事件时，仅更新本地状态中那条"临时 AI 消息"的 `id`，将其从"临时状态"转为"持久状态"。
        *   实现**去重合并策略**：在 `selectChat` 函数中，使用 `merge(prev, fetched)` 逻辑，通过 ID 判断，如果本地已经有了的消息，不要用后端的空数据去覆盖它。
    *   *技术亮点：*
        *   **状态即事实来源（State as Source of Truth）**：前端本地状态在交互期间是"事实来源"，而不是数据库。
        *   **最小化同步（Minimal Synchronization）**：只同步必要的数据（ID），而不是全量刷新。
        *   **防御性编程（Defensive Programming）**：合并策略保护本地有内容的消息不被后端空数据覆盖。

---

## 💡 技术沉淀与面试谈点 (Flashcards)

### 1. 为什么选择 SSE 而不是简单的 REST 请求？
*   **回答：** 提升 **TTFT (首屏交互时间)**。传统 REST 需等待 AI 几十秒生成完毕，SSE 可以让用户在数百毫秒内看到首字，显著降低了用户的感知延迟。

### 2. 在全栈联调中如何处理跨域 (CORS)？
*   **回答：** 在 NestJS 中配置了 `enableCors` 插件，精准授权 `http://localhost:3000`。理解了简单请求与预检请求（OPTIONS）的区别。

### 3. 如何处理 Read-after-write（写后立即读）的不一致性？
*   **回答：** 在本次项目解决"消息消失"Bug 中，我经历了从"Hack 修复"到"架构重构"的思考过程：
    *   **错误思路：** 用延迟（setTimeout）等待数据库提交，这是"用时间换正确性"，治标不治本。
    *   **正确思路：** 采用 **Optimistic UI（乐观更新）** + **状态本地固化**策略：
        1.  前端本地状态是交互期间的"事实来源"（Source of Truth）。
        2.  后端通过事件（`complete`）通知前端消息已持久化，只传递必要信息（ID）。
        3.  前端只做最小化同步（更新 ID），不做全量刷新。
        4.  合并策略保护本地有内容的消息不被后端空数据覆盖。
    *   **核心洞察：** 分布式系统中的一致性不是通过"等待"实现的，而是通过"事件驱动"和"状态协调"实现的。

---

## 📈 未来路线图 (Roadmap)
- [ ] **RAG 增强：** 接入向量数据库 (Milvus/Pinecone)，实现基于本地文档的知识检索。
- [ ] **高并发队列：** 引入 Redis (BullMQ) 处理大规模文档的异步切片与嵌入 (Embedding)。
- [ ] **性能监控：** 接入 Prometheus 监控 AI 响应延迟与令牌 (Tokens) 消耗。

---

### 📝 开发感悟与思考过程

#### 🎯 从 Hack 到架构的思考演进

**第一阶段：快速修复（Hack）**
- 遇到消息消失问题，第一反应是"延迟刷新"，用 `setTimeout` 等待数据库提交。
- **问题：** 这是典型的"用时间换正确性"，存在不可预知的竞态风险。

**第二阶段：深入思考（反思）**
- 意识到延迟不是解决方案，而是掩盖问题的遮羞布。
- 开始思考：为什么需要延迟？根本原因是什么？
- **发现：** 竞态条件的根源是"流式结束后立即全量刷新"的设计缺陷。

**第三阶段：架构重构（正确方案）**
- 转变策略：从"刷新获取"改为"状态固化"。
- 后端：确保消息在流关闭前已保存，通过事件通知前端。
- 前端：只做最小化同步（更新 ID），不做全量刷新。
- **结果：** 消除了竞态条件，代码更简洁、更可靠。

#### 💡 核心洞察

1.  **错误处理不是 try-catch，而是用户友好的错误映射层**
    - 将底层 API 错误（402、401）转换为业务语义（"余额不足"、"认证失败"）。
    - 提供重试机制，提升用户体验。

2.  **分布式系统中的一致性不是通过"等待"实现的**
    - 延迟刷新是"用时间换正确性"的 hack。
    - 正确做法是"事件驱动"和"状态协调"。

3.  **状态即事实来源（State as Source of Truth）**
    - 前端本地状态在交互期间是"事实来源"，而不是数据库。
    - 数据库是持久化层，不是实时状态层。

4.  **最小化同步原则**
    - 只同步必要的数据（ID），而不是全量刷新。
    - 减少网络请求，提升性能，降低竞态风险。

#### 🚀 技术亮点总结

1.  **分层错误处理架构**：后端错误映射 + 前端友好展示 + 重试机制
2.  **状态本地固化策略**：消除竞态条件，提升用户体验
3.  **去重合并算法**：保护本地状态不被后端空数据覆盖
4.  **事件驱动架构**：通过 `complete` 事件实现最小化同步

这两天的开发让我意识到，**软件工程不仅仅是写代码，更是关于"如何管理复杂性"和"如何处理不可靠的外部依赖（如 AI API）"**。从最初的静态页面到现在的全栈实时系统，每一个 Bug 的解决都是对系统底层原理（HTTP 协议、数据库事务、React 渲染机制）的深层复盘。更重要的是，**从 Hack 到架构的思考演进过程，让我学会了如何识别和解决根本问题，而不是掩盖症状**。
